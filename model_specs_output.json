{
  "id_tt-transformers_AFM-4.5B_n300": {
    "model_id": "id_tt-transformers_AFM-4.5B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "arcee-ai/AFM-4.5B",
    "model_name": "AFM-4.5B",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "ae65ee5",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "arcee-ai/AFM-4.5B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}",
        "override_generation_config": "{\"temperature\": 0.5, \"top_k\": 50, \"top_p\": 0.95}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "35f023f",
    "hf_weights_repo": "arcee-ai/AFM-4.5B",
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-ae65ee5-35f023f",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/ae65ee5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_AFM-4.5B_t3k": {
    "model_id": "id_tt-transformers_AFM-4.5B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "arcee-ai/AFM-4.5B",
    "model_name": "AFM-4.5B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "ae65ee5",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "arcee-ai/AFM-4.5B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}",
        "override_generation_config": "{\"temperature\": 0.5, \"top_k\": 50, \"top_p\": 0.95}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "35f023f",
    "hf_weights_repo": "arcee-ai/AFM-4.5B",
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-ae65ee5-35f023f",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/ae65ee5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_gemma-3-1b-it_n150": {
    "model_id": "id_tt-transformers_gemma-3-1b-it_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-1b-it",
    "model_name": "gemma-3-1b-it",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "google/gemma-3-1b-it",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 21448704, \"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 21448704,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/gemma-3-1b-it",
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 21448704,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_gemma-3-4b-it_n150": {
    "model_id": "id_tt-transformers_gemma-3-4b-it_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-4b-it",
    "model_name": "gemma-3-4b-it",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1980.0,
              "tput_user": 4.2,
              "tput": 134.4,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 396.0,
              "tput_user": 21.0,
              "tput": 672.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 198.0,
              "tput_user": 42.0,
              "tput": 1344.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/gemma-3-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 21448704, \"fabric_config\": \"FABRIC_1D\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 21448704,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/gemma-3-4b-it",
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 21448704,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_gemma-3-4b-it_n300": {
    "model_id": "id_tt-transformers_gemma-3-4b-it_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-4b-it",
    "model_name": "gemma-3-4b-it",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1330.0,
              "tput_user": 8.4,
              "tput": 268.8,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 266.0,
              "tput_user": 42.0,
              "tput": 1344.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 133.0,
              "tput_user": 84.0,
              "tput": 2688.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/gemma-3-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 21448704, \"fabric_config\": \"FABRIC_1D\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 21448704,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/gemma-3-4b-it",
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 21448704,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_medgemma-4b-it_n150": {
    "model_id": "id_tt-transformers_medgemma-4b-it_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/medgemma-4b-it",
    "model_name": "medgemma-4b-it",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1980.0,
              "tput_user": 4.2,
              "tput": 134.4,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 396.0,
              "tput_user": 21.0,
              "tput": 672.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 198.0,
              "tput_user": 42.0,
              "tput": 1344.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/medgemma-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 21448704, \"fabric_config\": \"FABRIC_1D\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 21448704,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/medgemma-4b-it",
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 21448704,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_medgemma-4b-it_n300": {
    "model_id": "id_tt-transformers_medgemma-4b-it_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/medgemma-4b-it",
    "model_name": "medgemma-4b-it",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1330.0,
              "tput_user": 8.4,
              "tput": 268.8,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 266.0,
              "tput_user": 42.0,
              "tput": 1344.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 133.0,
              "tput_user": 84.0,
              "tput": 2688.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/medgemma-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 21448704, \"fabric_config\": \"FABRIC_1D\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 21448704,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/medgemma-4b-it",
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 21448704,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_gemma-3-27b-it_t3k": {
    "model_id": "id_tt-transformers_gemma-3-27b-it_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-27b-it",
    "model_name": "gemma-3-27b-it",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8280.0,
              "tput_user": 5.0,
              "tput": 77.30000000000001,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1656.0,
              "tput_user": 25.0,
              "tput": 386.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 828.0,
              "tput_user": 50.0,
              "tput": 773.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/gemma-3-27b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 51934848, \"fabric_config\": \"FABRIC_1D\", \"sample_on_device_mode\": \"decode_only\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 51934848,
        "fabric_config": "FABRIC_1D",
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/gemma-3-27b-it",
    "param_count": 27,
    "min_disk_gb": 74,
    "min_ram_gb": 54.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 51934848,
      "fabric_config": "FABRIC_1D",
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_gemma-3-27b-it_galaxy_t3k": {
    "model_id": "id_tt-transformers_gemma-3-27b-it_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-27b-it",
    "model_name": "gemma-3-27b-it",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "google/gemma-3-27b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 21921792, \"fabric_config\": \"FABRIC_1D\", \"sample_on_device_mode\": \"decode_only\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 21921792,
        "fabric_config": "FABRIC_1D",
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/gemma-3-27b-it",
    "param_count": 27,
    "min_disk_gb": 74,
    "min_ram_gb": 54.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 21921792,
      "fabric_config": "FABRIC_1D",
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_medgemma-27b-it_t3k": {
    "model_id": "id_tt-transformers_medgemma-27b-it_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/medgemma-27b-it",
    "model_name": "medgemma-27b-it",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8280.0,
              "tput_user": 5.0,
              "tput": 77.30000000000001,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1656.0,
              "tput_user": 25.0,
              "tput": 386.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 828.0,
              "tput_user": 50.0,
              "tput": 773.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/medgemma-27b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 51934848, \"fabric_config\": \"FABRIC_1D\", \"sample_on_device_mode\": \"decode_only\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 51934848,
        "fabric_config": "FABRIC_1D",
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/medgemma-27b-it",
    "param_count": 27,
    "min_disk_gb": 74,
    "min_ram_gb": 54.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 51934848,
      "fabric_config": "FABRIC_1D",
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_medgemma-27b-it_galaxy_t3k": {
    "model_id": "id_tt-transformers_medgemma-27b-it_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/medgemma-27b-it",
    "model_name": "medgemma-27b-it",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "c254ee3",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "google/medgemma-27b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 24576, \"worker_l1_size\": 1344544, \"trace_region_size\": 21921792, \"fabric_config\": \"FABRIC_1D\", \"sample_on_device_mode\": \"decode_only\"}",
        "limit-mm-per-prompt": "{\"image\": 10}"
      },
      "override_tt_config": {
        "l1_small_size": 24576,
        "worker_l1_size": 1344544,
        "trace_region_size": 21921792,
        "fabric_config": "FABRIC_1D",
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "VLLM_USE_V1": "1",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "VLLM_USE_V1": "1",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "c4f2327",
    "hf_weights_repo": "google/medgemma-27b-it",
    "param_count": 27,
    "min_disk_gb": 74,
    "min_ram_gb": 54.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c254ee3-c4f2327",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c254ee3/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 24576,
      "worker_l1_size": 1344544,
      "trace_region_size": 21921792,
      "fabric_config": "FABRIC_1D",
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-3B-Instruct_n150": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-3B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-3B-Instruct",
    "model_name": "Qwen2.5-VL-3B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 330.0,
              "tput_user": 5.6000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 66.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 33.0,
              "tput_user": 56.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-3B-Instruct",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-3B-Instruct_n300": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-3B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-3B-Instruct",
    "model_name": "Qwen2.5-VL-3B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 540.0,
              "tput_user": 10.200000000000001,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 108.0,
              "tput_user": 51.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 54.0,
              "tput_user": 102.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-3B-Instruct",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-3B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-3B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-3B-Instruct",
    "model_name": "Qwen2.5-VL-3B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 220.0,
              "tput_user": 100.9,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 44.0,
              "tput_user": 504.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 22.0,
              "tput_user": 1009.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-3B-Instruct",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-7B-Instruct_n150": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-7B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-7B-Instruct",
    "model_name": "Qwen2.5-VL-7B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 660.0,
              "tput_user": 2.4000000000000004,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 132.0,
              "tput_user": 12.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 66.0,
              "tput_user": 24.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-7B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-7B-Instruct",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-7B-Instruct_n300": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-7B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-7B-Instruct",
    "model_name": "Qwen2.5-VL-7B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 800.0,
              "tput_user": 4.5,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 160.0,
              "tput_user": 22.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 80.0,
              "tput_user": 45.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-7B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-7B-Instruct",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-7B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-7B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-7B-Instruct",
    "model_name": "Qwen2.5-VL-7B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 270.0,
              "tput_user": 53.800000000000004,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 54.0,
              "tput_user": 269.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 27.0,
              "tput_user": 538.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-7B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-7B-Instruct",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-32B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-32B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-32B-Instruct",
    "model_name": "Qwen2.5-VL-32B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 630.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 126.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 63.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-32B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-32B-Instruct",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-VL-72B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-VL-72B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-VL-72B-Instruct",
    "model_name": "Qwen2.5-VL-72B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "c18569e",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3120.0,
              "tput_user": 2.0,
              "tput": 58.1,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 624.0,
              "tput_user": 10.0,
              "tput": 290.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 312.0,
              "tput_user": 20.0,
              "tput": 581.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-VL-72B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 28467200}"
      },
      "override_tt_config": {
        "trace_region_size": 28467200
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "b2894d3",
    "hf_weights_repo": "Qwen/Qwen2.5-VL-72B-Instruct",
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 144.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-c18569e-b2894d3",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c18569e/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 28467200
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-8B_n150": {
    "model_id": "id_tt-transformers_Qwen3-8B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 510.0,
              "tput_user": 2.1,
              "tput": 65.2,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 102.0,
              "tput_user": 10.5,
              "tput": 326.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 51.0,
              "tput_user": 21.0,
              "tput": 652.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-8B_n300": {
    "model_id": "id_tt-transformers_Qwen3-8B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 420.0,
              "tput_user": 4.1000000000000005,
              "tput": 130.3,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 84.0,
              "tput_user": 20.5,
              "tput": 651.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 42.0,
              "tput_user": 41.0,
              "tput": 1303.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-8B_t3k": {
    "model_id": "id_tt-transformers_Qwen3-8B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 220.0,
              "tput_user": 8.1,
              "tput": 521.2,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 44.0,
              "tput_user": 40.5,
              "tput": 2606.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 22.0,
              "tput_user": 81.0,
              "tput": 5212.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-8B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen3-8B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-8B_galaxy": {
    "model_id": "id_tt-transformers_Qwen3-8B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 220.0,
              "tput_user": 8.1,
              "tput": 2084.8,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 44.0,
              "tput_user": 40.5,
              "tput": 10424.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 22.0,
              "tput_user": 81.0,
              "tput": 20848.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4}"
      },
      "override_tt_config": {
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_qwen3-32b-galaxy_Qwen3-32B_galaxy": {
    "model_id": "id_qwen3-32b-galaxy_Qwen3-32B_galaxy",
    "impl": {
      "impl_id": "qwen3_32b_galaxy",
      "impl_name": "qwen3-32b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 15.600000000000001,
              "tput": 532.9,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 78.0,
              "tput": 2664.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 156.0,
              "tput": 5329.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1344544,
        "trace_region_size": 184915840
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "Qwen/Qwen3-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1344544,
      "trace_region_size": 184915840
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_tt-transformers_Qwen3-32B_t3k": {
    "model_id": "id_tt-transformers_Qwen3-32B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 620.0,
              "tput_user": 4.1000000000000005,
              "tput": 133.20000000000002,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 124.0,
              "tput_user": 20.5,
              "tput": 666.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 62.0,
              "tput_user": 41.0,
              "tput": 1332.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-32B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen3-32B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-32B_galaxy": {
    "model_id": "id_tt-transformers_Qwen3-32B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": false,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 620.0,
              "tput_user": 4.1000000000000005,
              "tput": 532.8000000000001,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 124.0,
              "tput_user": 20.5,
              "tput": 2664.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 62.0,
              "tput_user": 41.0,
              "tput": 5328.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4, \"trace_region_size\": 66147328, \"sample_on_device_mode\": \"decode_only\"}"
      },
      "override_tt_config": {
        "data_parallel": 4,
        "trace_region_size": 66147328,
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/Qwen3-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4,
      "trace_region_size": 66147328,
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-32B_p150x4": {
    "model_id": "id_tt-transformers_Qwen3-32B_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "inference_engine": "vLLM",
    "device_type": "P150X4",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "Qwen/Qwen3-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen3-32B_p150x8": {
    "model_id": "id_tt-transformers_Qwen3-32B_p150x8",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "inference_engine": "vLLM",
    "device_type": "P150X8",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X8",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "P150x8",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "P150x8",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "Qwen/Qwen3-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Mistral-7B-Instruct-v0.3_n150": {
    "model_id": "id_tt-transformers_Mistral-7B-Instruct-v0.3_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "model_name": "Mistral-7B-Instruct-v0.3",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 780.0,
              "tput_user": 7.0,
              "tput": 209.10000000000002,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 156.0,
              "tput_user": 35.0,
              "tput": 1045.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 78.0,
              "tput_user": 70.0,
              "tput": 2091.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "mistralai/Mistral-7B-Instruct-v0.3",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Mistral-7B-Instruct-v0.3_n300": {
    "model_id": "id_tt-transformers_Mistral-7B-Instruct-v0.3_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "model_name": "Mistral-7B-Instruct-v0.3",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "mistralai/Mistral-7B-Instruct-v0.3",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Mistral-7B-Instruct-v0.3_t3k": {
    "model_id": "id_tt-transformers_Mistral-7B-Instruct-v0.3_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "model_name": "Mistral-7B-Instruct-v0.3",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "mistralai/Mistral-7B-Instruct-v0.3",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_QwQ-32B_t3k": {
    "model_id": "id_tt-transformers_QwQ-32B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/QwQ-32B",
    "model_name": "QwQ-32B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 630.0,
              "tput_user": 4.1000000000000005,
              "tput": 132.5,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 126.0,
              "tput_user": 20.5,
              "tput": 662.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 63.0,
              "tput_user": 41.0,
              "tput": 1325.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/QwQ-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/QwQ-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_QwQ-32B_galaxy": {
    "model_id": "id_tt-transformers_QwQ-32B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/QwQ-32B",
    "model_name": "QwQ-32B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 630.0,
              "tput_user": 4.1000000000000005,
              "tput": 530.0,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 126.0,
              "tput_user": 20.5,
              "tput": 2650.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 63.0,
              "tput_user": 41.0,
              "tput": 5300.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/QwQ-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 27381760, \"data_parallel\": 4}"
      },
      "override_tt_config": {
        "trace_region_size": 27381760,
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/QwQ-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 27381760,
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_QwQ-32B_galaxy_t3k": {
    "model_id": "id_tt-transformers_QwQ-32B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/QwQ-32B",
    "model_name": "QwQ-32B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "e95ffa5",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/QwQ-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "48eba14",
    "hf_weights_repo": "Qwen/QwQ-32B",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-e95ffa5-48eba14",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/e95ffa5/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-72B_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B",
    "model_name": "Qwen2.5-72B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "13f44c5",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1210.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 242.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 121.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 38720.0,
              "tput_user": 2.0,
              "tput": 64.0,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 7744.0,
              "tput_user": 10.0,
              "tput": 320.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 3872.0,
              "tput_user": 20.0,
              "tput": 640.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30712832}"
      },
      "override_tt_config": {
        "trace_region_size": 30712832
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "0edd242",
    "hf_weights_repo": "Qwen/Qwen2.5-72B",
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 144.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-13f44c5-0edd242",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/13f44c5/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30712832
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-72B_galaxy": {
    "model_id": "id_tt-transformers_Qwen2.5-72B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B",
    "model_name": "Qwen2.5-72B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "13f44c5",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1210.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 242.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 121.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 128,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 38720.0,
              "tput_user": 2.0,
              "tput": 256.0,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 7744.0,
              "tput_user": 10.0,
              "tput": 1280.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 3872.0,
              "tput_user": 20.0,
              "tput": 2560.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30712832, \"data_parallel\": 4}"
      },
      "override_tt_config": {
        "trace_region_size": 30712832,
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "0edd242",
    "hf_weights_repo": "Qwen/Qwen2.5-72B",
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 144.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-13f44c5-0edd242",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/13f44c5/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30712832,
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-72B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B",
    "model_name": "Qwen2.5-72B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "13f44c5",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30712832, \"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "trace_region_size": 30712832,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "0edd242",
    "hf_weights_repo": "Qwen/Qwen2.5-72B",
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 144.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-13f44c5-0edd242",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/13f44c5/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30712832,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-72B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5-72B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "13f44c5",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1210.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 242.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 121.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 38720.0,
              "tput_user": 2.0,
              "tput": 64.0,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 7744.0,
              "tput_user": 10.0,
              "tput": 320.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 3872.0,
              "tput_user": 20.0,
              "tput": 640.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30712832}"
      },
      "override_tt_config": {
        "trace_region_size": 30712832
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "0edd242",
    "hf_weights_repo": "Qwen/Qwen2.5-72B-Instruct",
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 144.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-13f44c5-0edd242",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/13f44c5/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30712832
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy": {
    "model_id": "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5-72B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "13f44c5",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1210.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 242.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 121.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 128,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 38720.0,
              "tput_user": 2.0,
              "tput": 256.0,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 7744.0,
              "tput_user": 10.0,
              "tput": 1280.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 3872.0,
              "tput_user": 20.0,
              "tput": 2560.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30712832, \"data_parallel\": 4}"
      },
      "override_tt_config": {
        "trace_region_size": 30712832,
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "0edd242",
    "hf_weights_repo": "Qwen/Qwen2.5-72B-Instruct",
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 144.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-13f44c5-0edd242",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/13f44c5/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30712832,
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5-72B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "13f44c5",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30712832, \"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "trace_region_size": 30712832,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "0edd242",
    "hf_weights_repo": "Qwen/Qwen2.5-72B-Instruct",
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 144.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-13f44c5-0edd242",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/13f44c5/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30712832,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-7B_n300": {
    "model_id": "id_tt-transformers_Qwen2.5-7B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B",
    "model_name": "Qwen2.5-7B",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "5b5db8a",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 160.0,
              "tput_user": 6.6000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 32.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 16.0,
              "tput_user": 66.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "e771fff",
    "hf_weights_repo": "Qwen/Qwen2.5-7B",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5b5db8a-e771fff",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5b5db8a/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-7B_n150x4": {
    "model_id": "id_tt-transformers_Qwen2.5-7B_n150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B",
    "model_name": "Qwen2.5-7B",
    "inference_engine": "vLLM",
    "device_type": "N150X4",
    "tt_metal_commit": "5b5db8a",
    "device_model_spec": {
      "device": "N150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150x4",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150x4",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "e771fff",
    "hf_weights_repo": "Qwen/Qwen2.5-7B",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5b5db8a-e771fff",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5b5db8a/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-7B-Instruct_n300": {
    "model_id": "id_tt-transformers_Qwen2.5-7B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B-Instruct",
    "model_name": "Qwen2.5-7B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "5b5db8a",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 160.0,
              "tput_user": 6.6000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 32.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 16.0,
              "tput_user": 66.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "e771fff",
    "hf_weights_repo": "Qwen/Qwen2.5-7B-Instruct",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5b5db8a-e771fff",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5b5db8a/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-7B-Instruct_n150x4": {
    "model_id": "id_tt-transformers_Qwen2.5-7B-Instruct_n150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B-Instruct",
    "model_name": "Qwen2.5-7B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N150X4",
    "tt_metal_commit": "5b5db8a",
    "device_model_spec": {
      "device": "N150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150x4",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150x4",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "e771fff",
    "hf_weights_repo": "Qwen/Qwen2.5-7B-Instruct",
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5b5db8a-e771fff",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5b5db8a/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_llama3-70b-galaxy_Llama-3.3-70B-Instruct_galaxy": {
    "model_id": "id_llama3-70b-galaxy_Llama-3.3-70B-Instruct_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1344544,
        "trace_region_size": 184915840
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1344544,
      "trace_region_size": 184915840
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_llama3-70b-galaxy_Llama-3.1-70B_galaxy": {
    "model_id": "id_llama3-70b-galaxy_Llama-3.1-70B_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1344544,
        "trace_region_size": 184915840
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1344544,
      "trace_region_size": 184915840
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_llama3-70b-galaxy_Llama-3.1-70B-Instruct_galaxy": {
    "model_id": "id_llama3-70b-galaxy_Llama-3.1-70B-Instruct_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1344544,
        "trace_region_size": 184915840
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1344544,
      "trace_region_size": 184915840
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_llama3-70b-galaxy_DeepSeek-R1-Distill-Llama-70B_galaxy": {
    "model_id": "id_llama3-70b-galaxy_DeepSeek-R1-Distill-Llama-70B_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1344544,
        "trace_region_size": 184915840
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1344544,
      "trace_region_size": 184915840
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_tt-transformers_Llama-3.3-70B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.3-70B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_t3k": {
    "model_id": "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.3-70B-Instruct_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.3-70B-Instruct_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P150X4",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-70B_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "inference_engine": "vLLM",
    "device_type": "P150X4",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B-Instruct_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-70B-Instruct_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P150X4",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_p150x4": {
    "model_id": "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "inference_engine": "vLLM",
    "device_type": "P150X4",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.3-70B-Instruct_p150x8": {
    "model_id": "id_tt-transformers_Llama-3.3-70B-Instruct_p150x8",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P150X8",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X8",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 640.0,
              "tput_user": 1.8,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 128.0,
              "tput_user": 9.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 64.0,
              "tput_user": 18.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x8",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x8",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B_p150x8": {
    "model_id": "id_tt-transformers_Llama-3.1-70B_p150x8",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "inference_engine": "vLLM",
    "device_type": "P150X8",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X8",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 640.0,
              "tput_user": 1.8,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 128.0,
              "tput_user": 9.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 64.0,
              "tput_user": 18.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x8",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x8",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B-Instruct_p150x8": {
    "model_id": "id_tt-transformers_Llama-3.1-70B-Instruct_p150x8",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P150X8",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X8",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 640.0,
              "tput_user": 1.8,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 128.0,
              "tput_user": 9.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 64.0,
              "tput_user": 18.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x8",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x8",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_p150x8": {
    "model_id": "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_p150x8",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "inference_engine": "vLLM",
    "device_type": "P150X8",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X8",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 640.0,
              "tput_user": 1.8,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 128.0,
              "tput_user": 9.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 64.0,
              "tput_user": 18.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 71045120}"
      },
      "override_tt_config": {
        "trace_region_size": 71045120
      },
      "env_vars": {
        "MESH_DEVICE": "P150x8",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x8",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 71045120
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.3-70B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.3-70B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "e7c329b",
    "hf_weights_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "e7c329b",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-70B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "e7c329b",
    "hf_weights_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_galaxy_t3k": {
    "model_id": "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "e7c329b",
    "hf_weights_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 140.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-11B-Vision_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision",
    "model_name": "Llama-3.2-11B-Vision",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3390.0,
              "tput_user": 3.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 678.0,
              "tput_user": 15.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 339.0,
              "tput_user": 31.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "hf_weights_repo": "meta-llama/Llama-3.2-11B-Vision",
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 44.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-11B-Vision_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision",
    "model_name": "Llama-3.2-11B-Vision",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 950.0,
              "tput_user": 12.200000000000001,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 190.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 95.0,
              "tput_user": 122.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "hf_weights_repo": "meta-llama/Llama-3.2-11B-Vision",
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 22.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "model_name": "Llama-3.2-11B-Vision-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3390.0,
              "tput_user": 3.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 678.0,
              "tput_user": 15.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 339.0,
              "tput_user": 31.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "hf_weights_repo": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 44.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "model_name": "Llama-3.2-11B-Vision-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 950.0,
              "tput_user": 12.200000000000001,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 190.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 95.0,
              "tput_user": 122.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "hf_weights_repo": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 22.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-90B-Vision_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-90B-Vision_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-90B-Vision",
    "model_name": "Llama-3.2-90B-Vision",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3030.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 606.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 303.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-90B-Vision",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": 16
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": 16
    },
    "vllm_commit": "5cbc982",
    "hf_weights_repo": "meta-llama/Llama-3.2-90B-Vision",
    "param_count": 90,
    "min_disk_gb": 200,
    "min_ram_gb": 180.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-90B-Vision-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-90B-Vision-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-90B-Vision-Instruct",
    "model_name": "Llama-3.2-90B-Vision-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3030.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 606.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 303.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-90B-Vision-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": 16
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": 16
    },
    "vllm_commit": "5cbc982",
    "hf_weights_repo": "meta-llama/Llama-3.2-90B-Vision-Instruct",
    "param_count": 90,
    "min_disk_gb": 200,
    "min_ram_gb": 180.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-1B_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-1B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B",
    "model_name": "Llama-3.2-1B",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.2-1B",
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-1B_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-1B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B",
    "model_name": "Llama-3.2-1B",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.2-1B",
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-1B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-1B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B",
    "model_name": "Llama-3.2-1B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.2-1B",
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-1B-Instruct_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-1B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "model_name": "Llama-3.2-1B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-1B-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-1B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "model_name": "Llama-3.2-1B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-1B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-1B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "model_name": "Llama-3.2-1B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "hf_weights_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-3B_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-3B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B",
    "model_name": "Llama-3.2-3B",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "hf_weights_repo": "meta-llama/Llama-3.2-3B",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-3B_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-3B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B",
    "model_name": "Llama-3.2-3B",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "hf_weights_repo": "meta-llama/Llama-3.2-3B",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-3B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-3B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B",
    "model_name": "Llama-3.2-3B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "hf_weights_repo": "meta-llama/Llama-3.2-3B",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-3B-Instruct_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-3B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama-3.2-3B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "hf_weights_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-3B-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-3B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama-3.2-3B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "hf_weights_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.2-3B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-3B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama-3.2-3B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "hf_weights_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_n150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 890.0,
              "tput_user": 2.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 178.0,
              "tput_user": 10.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 89.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_n300": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 580.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 116.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 58.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 33000000}"
      },
      "override_tt_config": {
        "trace_region_size": 33000000
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 33000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 230.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 46.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 23.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 8,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 10880.0,
              "tput_user": 6.6819999999999995,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 2176.0,
              "tput_user": 33.41,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 1088.0,
              "tput_user": 66.82,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 50000000}"
      },
      "override_tt_config": {
        "trace_region_size": 50000000
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 50000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_gpu": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_gpu",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "GPU",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "GPU",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": false,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "GPU"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "GPU"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_n150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N150",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 890.0,
              "tput_user": 2.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 178.0,
              "tput_user": 10.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 89.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "N300",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 580.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 116.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 58.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 33000000}"
      },
      "override_tt_config": {
        "trace_region_size": 33000000
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 33000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 230.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 46.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 23.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 8,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 10880.0,
              "tput_user": 6.6819999999999995,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 2176.0,
              "tput_user": 33.41,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 1088.0,
              "tput_user": 66.82,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 50000000}"
      },
      "override_tt_config": {
        "trace_region_size": 50000000
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 50000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_gpu": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_gpu",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GPU",
    "tt_metal_commit": "25305db",
    "device_model_spec": {
      "device": "GPU",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": false,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "GPU"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "GPU"
    },
    "vllm_commit": "6e67d2d",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-25305db-6e67d2d",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/25305db/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_p100": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_p100",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "P100",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P100",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 570.0,
              "tput_user": 3.3000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 114.0,
              "tput_user": 16.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 57.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P100",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P100",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_p150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_p150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "P150",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "P150",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_p100": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_p100",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P100",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P100",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 570.0,
              "tput_user": 3.3000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 114.0,
              "tput_user": 16.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 57.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P100",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P100",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_p150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_p150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P150",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "P150",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "P150X4",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4, \"sample_on_device_mode\": \"decode_only\", \"trace_region_size\": 42000000}"
      },
      "override_tt_config": {
        "data_parallel": 4,
        "sample_on_device_mode": "decode_only",
        "trace_region_size": 42000000
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4,
      "sample_on_device_mode": "decode_only",
      "trace_region_size": 42000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "P150",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P150X4",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4, \"sample_on_device_mode\": \"decode_only\", \"trace_region_size\": 42000000}"
      },
      "override_tt_config": {
        "data_parallel": 4,
        "sample_on_device_mode": "decode_only",
        "trace_region_size": 42000000
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4,
      "sample_on_device_mode": "decode_only",
      "trace_region_size": 42000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "P150",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_p150x8": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_p150x8",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "P150X8",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X8",
      "max_concurrency": 256,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "256",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 8, \"sample_on_device_mode\": \"decode_only\"}"
      },
      "override_tt_config": {
        "data_parallel": 8,
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "MESH_DEVICE": "P150x8",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x8",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 8,
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "P150",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_p150x8": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_p150x8",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "P150X8",
    "tt_metal_commit": "7665133",
    "device_model_spec": {
      "device": "P150X8",
      "max_concurrency": 256,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "256",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 8, \"sample_on_device_mode\": \"decode_only\"}"
      },
      "override_tt_config": {
        "data_parallel": 8,
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "MESH_DEVICE": "P150x8",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.12.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.4.1",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x8",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "e25b4d7",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-7665133-e25b4d7",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/7665133/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 8,
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "P150",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Llama-3.1-8B_galaxy": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 230.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 46.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 23.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 10880.0,
              "tput_user": 6.6819999999999995,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 2176.0,
              "tput_user": 33.41,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 1088.0,
              "tput_user": 66.82,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 50000000, \"data_parallel\": 4, \"sample_on_device_mode\": \"all\"}"
      },
      "override_tt_config": {
        "trace_region_size": 50000000,
        "data_parallel": 4,
        "sample_on_device_mode": "all"
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 50000000,
      "data_parallel": 4,
      "sample_on_device_mode": "all"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_tt-transformers_Llama-3.1-8B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "trace_region_size": 50000000,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "trace_region_size": 50000000,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 230.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 46.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 23.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 256,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 10880.0,
              "tput_user": 6.6819999999999995,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 2176.0,
              "tput_user": 33.41,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 1088.0,
              "tput_user": 66.82,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 50000000, \"data_parallel\": 4, \"sample_on_device_mode\": \"all\"}"
      },
      "override_tt_config": {
        "trace_region_size": 50000000,
        "data_parallel": 4,
        "sample_on_device_mode": "all"
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 50000000,
      "data_parallel": 4,
      "sample_on_device_mode": "all"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "trace_region_size": 50000000,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "trace_region_size": 50000000,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "f49265a",
    "hf_weights_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-5491d3c-f49265a",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": true
  },
  "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "model_name": "Qwen2.5-Coder-32B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "T3K",
    "tt_metal_commit": "17a5973",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 630.0,
              "tput_user": 4.1000000000000005,
              "tput": 132.5,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 126.0,
              "tput_user": 20.5,
              "tput": 662.5,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 63.0,
              "tput_user": 41.0,
              "tput": 1325.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "aa4ae1e",
    "hf_weights_repo": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-17a5973-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/17a5973/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "model_name": "Qwen2.5-Coder-32B-Instruct",
    "inference_engine": "vLLM",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "17a5973",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.textproto"
    },
    "vllm_commit": "aa4ae1e",
    "hf_weights_repo": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 64.0,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.7.0-17a5973-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/17a5973/models/tt_transformers",
    "override_tt_config": {
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_n150": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "inference_engine": "media",
    "device_type": "N150",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_n300": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "inference_engine": "media",
    "device_type": "N300",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_t3k": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 4,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_galaxy": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 32,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_n150": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
    "model_name": "stable-diffusion-xl-base-1.0-img-2-img",
    "inference_engine": "media",
    "device_type": "N150",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_n300": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
    "model_name": "stable-diffusion-xl-base-1.0-img-2-img",
    "inference_engine": "media",
    "device_type": "N300",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_t3k": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
    "model_name": "stable-diffusion-xl-base-1.0-img-2-img",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 4,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_galaxy": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0-img-2-img_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
    "model_name": "stable-diffusion-xl-base-1.0-img-2-img",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 32,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0-img-2-img",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-3.5-large_t3k": {
    "model_id": "id_tt-transformers_stable-diffusion-3.5-large_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-3.5-large",
    "model_name": "stable-diffusion-3.5-large",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 110000.0,
              "tput_user": 0.0091,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 22000.0,
              "tput_user": 0.0455,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 11000.0,
              "tput_user": 0.091,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-3.5-large",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-3.5-large",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-3.5-large_galaxy": {
    "model_id": "id_tt-transformers_stable-diffusion-3.5-large_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-3.5-large",
    "model_name": "stable-diffusion-3.5-large",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 50000.0,
              "tput_user": 0.020000000000000004,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 10000.0,
              "tput_user": 0.1,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 5000.0,
              "tput_user": 0.2,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-3.5-large",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "stabilityai/stable-diffusion-3.5-large",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_n150": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "model_name": "stable-diffusion-xl-1.0-inpainting-0.1",
    "inference_engine": "media",
    "device_type": "N150",
    "tt_metal_commit": "fbbbd2d",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 110000.0,
              "tput_user": 0.0091,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 22000.0,
              "tput_user": 0.0455,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 11000.0,
              "tput_user": 0.091,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.5.0-fbbbd2da8cfab49ddf43d28dd9c0813a3c3ee2bd",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/fbbbd2d/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_n300": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "model_name": "stable-diffusion-xl-1.0-inpainting-0.1",
    "inference_engine": "media",
    "device_type": "N300",
    "tt_metal_commit": "fbbbd2d",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.5.0-fbbbd2da8cfab49ddf43d28dd9c0813a3c3ee2bd",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/fbbbd2d/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_t3k": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "model_name": "stable-diffusion-xl-1.0-inpainting-0.1",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "fbbbd2d",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.5.0-fbbbd2da8cfab49ddf43d28dd9c0813a3c3ee2bd",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/fbbbd2d/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_galaxy": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-1.0-inpainting-0.1_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "model_name": "stable-diffusion-xl-1.0-inpainting-0.1",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "fbbbd2d",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "IMAGE",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.5.0-fbbbd2da8cfab49ddf43d28dd9c0813a3c3ee2bd",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/fbbbd2d/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_FLUX.1-dev_t3k": {
    "model_id": "id_tt-transformers_FLUX.1-dev_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "black-forest-labs/FLUX.1-dev",
    "model_name": "FLUX.1-dev",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "black-forest-labs/FLUX.1-dev",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "black-forest-labs/FLUX.1-dev",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_FLUX.1-dev_galaxy": {
    "model_id": "id_tt-transformers_FLUX.1-dev_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "black-forest-labs/FLUX.1-dev",
    "model_name": "FLUX.1-dev",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "black-forest-labs/FLUX.1-dev",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "black-forest-labs/FLUX.1-dev",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_FLUX.1-schnell_t3k": {
    "model_id": "id_tt-transformers_FLUX.1-schnell_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "black-forest-labs/FLUX.1-schnell",
    "model_name": "FLUX.1-schnell",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "black-forest-labs/FLUX.1-schnell",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "black-forest-labs/FLUX.1-schnell",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_FLUX.1-schnell_galaxy": {
    "model_id": "id_tt-transformers_FLUX.1-schnell_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "black-forest-labs/FLUX.1-schnell",
    "model_name": "FLUX.1-schnell",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "black-forest-labs/FLUX.1-schnell",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "black-forest-labs/FLUX.1-schnell",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Motif-Image-6B-Preview_t3k": {
    "model_id": "id_tt-transformers_Motif-Image-6B-Preview_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Motif-Technologies/Motif-Image-6B-Preview",
    "model_name": "Motif-Image-6B-Preview",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Motif-Technologies/Motif-Image-6B-Preview",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Motif-Technologies/Motif-Image-6B-Preview",
    "param_count": 6,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Motif-Image-6B-Preview_galaxy": {
    "model_id": "id_tt-transformers_Motif-Image-6B-Preview_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Motif-Technologies/Motif-Image-6B-Preview",
    "model_name": "Motif-Image-6B-Preview",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Motif-Technologies/Motif-Image-6B-Preview",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Motif-Technologies/Motif-Image-6B-Preview",
    "param_count": 6,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_mochi-1-preview_t3k": {
    "model_id": "id_tt-transformers_mochi-1-preview_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "genmo/mochi-1-preview",
    "model_name": "mochi-1-preview",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "genmo/mochi-1-preview",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "genmo/mochi-1-preview",
    "param_count": null,
    "min_disk_gb": 60,
    "min_ram_gb": 32,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_mochi-1-preview_galaxy": {
    "model_id": "id_tt-transformers_mochi-1-preview_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "genmo/mochi-1-preview",
    "model_name": "mochi-1-preview",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "genmo/mochi-1-preview",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "genmo/mochi-1-preview",
    "param_count": null,
    "min_disk_gb": 60,
    "min_ram_gb": 32,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Wan2.2-T2V-A14B-Diffusers_t3k": {
    "model_id": "id_tt-transformers_Wan2.2-T2V-A14B-Diffusers_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
    "model_name": "Wan2.2-T2V-A14B-Diffusers",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
    "param_count": 14,
    "min_disk_gb": 60,
    "min_ram_gb": 32,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_Wan2.2-T2V-A14B-Diffusers_galaxy": {
    "model_id": "id_tt-transformers_Wan2.2-T2V-A14B-Diffusers_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
    "model_name": "Wan2.2-T2V-A14B-Diffusers",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "c180ef7",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
    "param_count": 14,
    "min_disk_gb": 60,
    "min_ram_gb": 32,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-c180ef7",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/c180ef7/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_whisper_whisper-large-v3_n150": {
    "model_id": "id_whisper_whisper-large-v3_n150",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "openai/whisper-large-v3",
    "model_name": "whisper-large-v3",
    "inference_engine": "media",
    "device_type": "N150",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 5.631,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 28.155,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 56.31,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "openai/whisper-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "openai/whisper-large-v3",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_whisper_whisper-large-v3_galaxy": {
    "model_id": "id_whisper_whisper-large-v3_galaxy",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "openai/whisper-large-v3",
    "model_name": "whisper-large-v3",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 32,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 6.555,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 32.775,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 65.55,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "openai/whisper-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "openai/whisper-large-v3",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_whisper_whisper-large-v3_t3k": {
    "model_id": "id_whisper_whisper-large-v3_t3k",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "openai/whisper-large-v3",
    "model_name": "whisper-large-v3",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 5.38,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 26.9,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 53.8,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "openai/whisper-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "openai/whisper-large-v3",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_whisper_distil-large-v3_n150": {
    "model_id": "id_whisper_distil-large-v3_n150",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "distil-whisper/distil-large-v3",
    "model_name": "distil-large-v3",
    "inference_engine": "media",
    "device_type": "N150",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 5.631,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 28.155,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 56.31,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "distil-whisper/distil-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "distil-whisper/distil-large-v3",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_whisper_distil-large-v3_galaxy": {
    "model_id": "id_whisper_distil-large-v3_galaxy",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "distil-whisper/distil-large-v3",
    "model_name": "distil-large-v3",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 32,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 6.555,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 32.775,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 65.55,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "distil-whisper/distil-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "distil-whisper/distil-large-v3",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_whisper_distil-large-v3_t3k": {
    "model_id": "id_whisper_distil-large-v3_t3k",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "distil-whisper/distil-large-v3",
    "model_name": "distil-large-v3",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "5491d3c",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 5.38,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 26.9,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 53.8,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "distil-whisper/distil-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "distil-whisper/distil-large-v3",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.7.0-5491d3c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/5491d3c/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-vllm-plugin_bge-large-en-v1.5_n150": {
    "model_id": "id_tt-vllm-plugin_bge-large-en-v1.5_n150",
    "impl": {
      "impl_id": "tt_vllm_plugin",
      "impl_name": "tt-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin",
      "code_path": "tt_vllm_plugin"
    },
    "hf_model_repo": "BAAI/bge-large-en-v1.5",
    "model_name": "bge-large-en-v1.5",
    "inference_engine": "media",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 3200.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 16000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 32000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "BAAI/bge-large-en-v1.5",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
        "VLLM__MAX_MODEL_LENGTH": "384",
        "VLLM__MIN_CONTEXT_LENGTH": "32"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
      "VLLM__MAX_MODEL_LENGTH": "384",
      "VLLM__MIN_CONTEXT_LENGTH": "32"
    },
    "vllm_commit": null,
    "hf_weights_repo": "BAAI/bge-large-en-v1.5",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin/tree/2496be4/tt_vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-vllm-plugin_bge-large-en-v1.5_n300": {
    "model_id": "id_tt-vllm-plugin_bge-large-en-v1.5_n300",
    "impl": {
      "impl_id": "tt_vllm_plugin",
      "impl_name": "tt-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin",
      "code_path": "tt_vllm_plugin"
    },
    "hf_model_repo": "BAAI/bge-large-en-v1.5",
    "model_name": "bge-large-en-v1.5",
    "inference_engine": "media",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 3200.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 16000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 32000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "BAAI/bge-large-en-v1.5",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
        "VLLM__MAX_MODEL_LENGTH": "384",
        "VLLM__MIN_CONTEXT_LENGTH": "32"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
      "VLLM__MAX_MODEL_LENGTH": "384",
      "VLLM__MIN_CONTEXT_LENGTH": "32"
    },
    "vllm_commit": null,
    "hf_weights_repo": "BAAI/bge-large-en-v1.5",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin/tree/2496be4/tt_vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-vllm-plugin_bge-large-en-v1.5_t3k": {
    "model_id": "id_tt-vllm-plugin_bge-large-en-v1.5_t3k",
    "impl": {
      "impl_id": "tt_vllm_plugin",
      "impl_name": "tt-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin",
      "code_path": "tt_vllm_plugin"
    },
    "hf_model_repo": "BAAI/bge-large-en-v1.5",
    "model_name": "bge-large-en-v1.5",
    "inference_engine": "media",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 4,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 3200.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 16000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 32000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "BAAI/bge-large-en-v1.5",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
        "VLLM__MAX_MODEL_LENGTH": "384",
        "VLLM__MIN_CONTEXT_LENGTH": "32"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
      "VLLM__MAX_MODEL_LENGTH": "384",
      "VLLM__MIN_CONTEXT_LENGTH": "32"
    },
    "vllm_commit": null,
    "hf_weights_repo": "BAAI/bge-large-en-v1.5",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin/tree/2496be4/tt_vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-vllm-plugin_bge-large-en-v1.5_galaxy": {
    "model_id": "id_tt-vllm-plugin_bge-large-en-v1.5_galaxy",
    "impl": {
      "impl_id": "tt_vllm_plugin",
      "impl_name": "tt-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin",
      "code_path": "tt_vllm_plugin"
    },
    "hf_model_repo": "BAAI/bge-large-en-v1.5",
    "model_name": "bge-large-en-v1.5",
    "inference_engine": "media",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 32,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 3200.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 16000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 32000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "BAAI/bge-large-en-v1.5",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
        "VLLM__MAX_MODEL_LENGTH": "384",
        "VLLM__MIN_CONTEXT_LENGTH": "32",
        "TT_METAL_INSPECTOR_RPC": "0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "3072",
      "VLLM__MAX_MODEL_LENGTH": "384",
      "VLLM__MIN_CONTEXT_LENGTH": "32",
      "TT_METAL_INSPECTOR_RPC": "0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "BAAI/bge-large-en-v1.5",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-inference-server/tree/dev/tt-vllm-plugin/tree/2496be4/tt_vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_forge-vllm-plugin_Qwen3-Embedding-4B_n150": {
    "model_id": "id_forge-vllm-plugin_Qwen3-Embedding-4B_n150",
    "impl": {
      "impl_id": "forge_vllm_plugin",
      "impl_name": "forge-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-xla/tree/main",
      "code_path": "integrations/vllm_plugin"
    },
    "hf_model_repo": "Qwen/Qwen3-Embedding-4B",
    "model_name": "Qwen3-Embedding-4B",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 600.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 3000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 6000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-Embedding-4B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
        "VLLM__MAX_MODEL_LENGTH": "1024",
        "VLLM__MIN_CONTEXT_LENGTH": "32"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
      "VLLM__MAX_MODEL_LENGTH": "1024",
      "VLLM__MIN_CONTEXT_LENGTH": "32"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Qwen/Qwen3-Embedding-4B",
    "param_count": 4,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-xla/tree/main/tree/2496be4/integrations/vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_forge-vllm-plugin_Qwen3-Embedding-4B_n300": {
    "model_id": "id_forge-vllm-plugin_Qwen3-Embedding-4B_n300",
    "impl": {
      "impl_id": "forge_vllm_plugin",
      "impl_name": "forge-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-xla/tree/main",
      "code_path": "integrations/vllm_plugin"
    },
    "hf_model_repo": "Qwen/Qwen3-Embedding-4B",
    "model_name": "Qwen3-Embedding-4B",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 600.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 3000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 6000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-Embedding-4B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
        "VLLM__MAX_MODEL_LENGTH": "1024",
        "VLLM__MIN_CONTEXT_LENGTH": "32"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
      "VLLM__MAX_MODEL_LENGTH": "1024",
      "VLLM__MIN_CONTEXT_LENGTH": "32"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Qwen/Qwen3-Embedding-4B",
    "param_count": 4,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-xla/tree/main/tree/2496be4/integrations/vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_forge-vllm-plugin_Qwen3-Embedding-4B_t3k": {
    "model_id": "id_forge-vllm-plugin_Qwen3-Embedding-4B_t3k",
    "impl": {
      "impl_id": "forge_vllm_plugin",
      "impl_name": "forge-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-xla/tree/main",
      "code_path": "integrations/vllm_plugin"
    },
    "hf_model_repo": "Qwen/Qwen3-Embedding-4B",
    "model_name": "Qwen3-Embedding-4B",
    "inference_engine": "forge",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 600.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 3000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 6000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-Embedding-4B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
        "VLLM__MAX_MODEL_LENGTH": "1024",
        "VLLM__MIN_CONTEXT_LENGTH": "32"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
      "VLLM__MAX_MODEL_LENGTH": "1024",
      "VLLM__MIN_CONTEXT_LENGTH": "32"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Qwen/Qwen3-Embedding-4B",
    "param_count": 4,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-xla/tree/main/tree/2496be4/integrations/vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_forge-vllm-plugin_Qwen3-Embedding-4B_galaxy": {
    "model_id": "id_forge-vllm-plugin_Qwen3-Embedding-4B_galaxy",
    "impl": {
      "impl_id": "forge_vllm_plugin",
      "impl_name": "forge-vllm-plugin",
      "repo_url": "https://github.com/tenstorrent/tt-xla/tree/main",
      "code_path": "integrations/vllm_plugin"
    },
    "hf_model_repo": "Qwen/Qwen3-Embedding-4B",
    "model_name": "Qwen3-Embedding-4B",
    "inference_engine": "forge",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "embedding",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": null,
              "tput_user": 600.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": null,
              "tput_user": 3000.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": null,
              "tput_user": 6000.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-Embedding-4B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
        "VLLM__MAX_MODEL_LENGTH": "1024",
        "VLLM__MIN_CONTEXT_LENGTH": "32"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "VLLM__MAX_NUM_BATCHED_TOKENS": "1024",
      "VLLM__MAX_MODEL_LENGTH": "1024",
      "VLLM__MIN_CONTEXT_LENGTH": "32"
    },
    "vllm_commit": null,
    "hf_weights_repo": "Qwen/Qwen3-Embedding-4B",
    "param_count": 4,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "EMBEDDING",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-xla/tree/main/tree/2496be4/integrations/vllm_plugin",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_resnet-50_n150": {
    "model_id": "id_tt-transformers_resnet-50_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "resnet-50",
    "model_name": "resnet-50",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "resnet-50",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "resnet-50",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_resnet-50_n300": {
    "model_id": "id_tt-transformers_resnet-50_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "resnet-50",
    "model_name": "resnet-50",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "resnet-50",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "resnet-50",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_vovnet_n150": {
    "model_id": "id_tt-transformers_vovnet_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "vovnet",
    "model_name": "vovnet",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "vovnet",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "vovnet",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_vovnet_n300": {
    "model_id": "id_tt-transformers_vovnet_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "vovnet",
    "model_name": "vovnet",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "vovnet",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "vovnet",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_mobilenetv2_n150": {
    "model_id": "id_tt-transformers_mobilenetv2_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mobilenetv2",
    "model_name": "mobilenetv2",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 6000.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1200.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 600.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "mobilenetv2",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "mobilenetv2",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_mobilenetv2_n300": {
    "model_id": "id_tt-transformers_mobilenetv2_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mobilenetv2",
    "model_name": "mobilenetv2",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "mobilenetv2",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "mobilenetv2",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_efficientnet_n150": {
    "model_id": "id_tt-transformers_efficientnet_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "efficientnet",
    "model_name": "efficientnet",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "efficientnet",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "efficientnet",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_efficientnet_n300": {
    "model_id": "id_tt-transformers_efficientnet_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "efficientnet",
    "model_name": "efficientnet",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "efficientnet",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "efficientnet",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_segformer_n150": {
    "model_id": "id_tt-transformers_segformer_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "segformer",
    "model_name": "segformer",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "segformer",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "segformer",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_segformer_n300": {
    "model_id": "id_tt-transformers_segformer_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "segformer",
    "model_name": "segformer",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "segformer",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "segformer",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_vit_n150": {
    "model_id": "id_tt-transformers_vit_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "vit",
    "model_name": "vit",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "vit",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "vit",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_vit_n300": {
    "model_id": "id_tt-transformers_vit_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "vit",
    "model_name": "vit",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "vit",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "vit",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_unet_n150": {
    "model_id": "id_tt-transformers_unet_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "unet",
    "model_name": "unet",
    "inference_engine": "forge",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "unet",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "unet",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  },
  "id_tt-transformers_unet_n300": {
    "model_id": "id_tt-transformers_unet_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "unet",
    "model_name": "unet",
    "inference_engine": "forge",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "unet",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "hf_weights_repo": "unet",
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.7.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null,
    "has_builtin_warmup": false
  }
}