{
  "id_tt-transformers_AFM-4.5B_n300": {
    "model_id": "id_tt-transformers_AFM-4.5B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "arcee-ai/AFM-4.5B",
    "model_name": "AFM-4.5B",
    "device_type": "N300",
    "tt_metal_commit": "ae65ee5",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "arcee-ai/AFM-4.5B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "35f023f",
    "custom_inference_server": null,
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-ae65ee5-35f023f",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/ae65ee5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_AFM-4.5B_t3k": {
    "model_id": "id_tt-transformers_AFM-4.5B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "arcee-ai/AFM-4.5B",
    "model_name": "AFM-4.5B",
    "device_type": "T3K",
    "tt_metal_commit": "ae65ee5",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "arcee-ai/AFM-4.5B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "35f023f",
    "custom_inference_server": null,
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-ae65ee5-35f023f",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/ae65ee5/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_gemma-3-1b-it_n150": {
    "model_id": "id_tt-transformers_gemma-3-1b-it_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-1b-it",
    "model_name": "gemma-3-1b-it",
    "device_type": "N150",
    "tt_metal_commit": "dc85f59",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "google/gemma-3-1b-it",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 768, \"fabric_config\": \"FABRIC_1D\"}"
      },
      "override_tt_config": {
        "l1_small_size": 768,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "87fe4a4",
    "custom_inference_server": null,
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 4,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-dc85f59-87fe4a4",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/dc85f59/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 768,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_gemma-3-4b-it_n150": {
    "model_id": "id_tt-transformers_gemma-3-4b-it_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-4b-it",
    "model_name": "gemma-3-4b-it",
    "device_type": "N150",
    "tt_metal_commit": "dc85f59",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1980.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 396.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 198.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/gemma-3-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 768, \"fabric_config\": \"FABRIC_1D\"}",
        "mm-processor-kwargs": "{\"use_fast\": true, \"do_convert_rgb\": true, \"do_pan_and_scan\": true}"
      },
      "override_tt_config": {
        "l1_small_size": 768,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "87fe4a4",
    "custom_inference_server": null,
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-dc85f59-87fe4a4",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/dc85f59/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 768,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_gemma-3-4b-it_n300": {
    "model_id": "id_tt-transformers_gemma-3-4b-it_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-4b-it",
    "model_name": "gemma-3-4b-it",
    "device_type": "N300",
    "tt_metal_commit": "dc85f59",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1330.0,
              "tput_user": 8.4,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 266.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 133.0,
              "tput_user": 84.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/gemma-3-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 768, \"fabric_config\": \"FABRIC_1D\"}",
        "mm-processor-kwargs": "{\"use_fast\": true, \"do_convert_rgb\": true, \"do_pan_and_scan\": true}"
      },
      "override_tt_config": {
        "l1_small_size": 768,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "87fe4a4",
    "custom_inference_server": null,
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-dc85f59-87fe4a4",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/dc85f59/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 768,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_medgemma-4b-it_n150": {
    "model_id": "id_tt-transformers_medgemma-4b-it_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/medgemma-4b-it",
    "model_name": "medgemma-4b-it",
    "device_type": "N150",
    "tt_metal_commit": "dc85f59",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1980.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 396.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 198.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/medgemma-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 768, \"fabric_config\": \"FABRIC_1D\"}",
        "mm-processor-kwargs": "{\"use_fast\": true, \"do_convert_rgb\": true, \"do_pan_and_scan\": true}"
      },
      "override_tt_config": {
        "l1_small_size": 768,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "87fe4a4",
    "custom_inference_server": null,
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-dc85f59-87fe4a4",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/dc85f59/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 768,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_medgemma-4b-it_n300": {
    "model_id": "id_tt-transformers_medgemma-4b-it_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/medgemma-4b-it",
    "model_name": "medgemma-4b-it",
    "device_type": "N300",
    "tt_metal_commit": "dc85f59",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1330.0,
              "tput_user": 8.4,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 266.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 133.0,
              "tput_user": 84.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/medgemma-4b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 768, \"fabric_config\": \"FABRIC_1D\"}",
        "mm-processor-kwargs": "{\"use_fast\": true, \"do_convert_rgb\": true, \"do_pan_and_scan\": true}"
      },
      "override_tt_config": {
        "l1_small_size": 768,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "87fe4a4",
    "custom_inference_server": null,
    "param_count": 4,
    "min_disk_gb": 28,
    "min_ram_gb": 16,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-dc85f59-87fe4a4",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/dc85f59/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 768,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_gemma-3-27b-it_t3k": {
    "model_id": "id_tt-transformers_gemma-3-27b-it_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/gemma-3-27b-it",
    "model_name": "gemma-3-27b-it",
    "device_type": "T3K",
    "tt_metal_commit": "17a5973",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8280.0,
              "tput_user": 5.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1656.0,
              "tput_user": 25.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 828.0,
              "tput_user": 50.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 16000,
          "osl": 64,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 3500,
          "image_width": 2500,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 121210.0,
              "tput_user": 5.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 24242.0,
              "tput_user": 25.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12121.0,
              "tput_user": 50.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 16000,
          "osl": 64,
          "max_concurrency": 32,
          "num_prompts": 128,
          "image_height": 3500,
          "image_width": 2500,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 121210.0,
              "tput_user": 5.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 24242.0,
              "tput_user": 25.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12121.0,
              "tput_user": 50.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/gemma-3-27b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 768, \"fabric_config\": \"FABRIC_1D\"}",
        "mm-processor-kwargs": "{\"use_fast\": true, \"do_convert_rgb\": true, \"do_pan_and_scan\": true}"
      },
      "override_tt_config": {
        "l1_small_size": 768,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 27,
    "min_disk_gb": 74,
    "min_ram_gb": 108,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-17a5973-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/17a5973/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 768,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_medgemma-27b-it_t3k": {
    "model_id": "id_tt-transformers_medgemma-27b-it_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "google/medgemma-27b-it",
    "model_name": "medgemma-27b-it",
    "device_type": "T3K",
    "tt_metal_commit": "17a5973",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 896,
          "image_width": 896,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8280.0,
              "tput_user": 5.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1656.0,
              "tput_user": 25.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 828.0,
              "tput_user": 50.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 16000,
          "osl": 64,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 3500,
          "image_width": 2500,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 121210.0,
              "tput_user": 5.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 24242.0,
              "tput_user": 25.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12121.0,
              "tput_user": 50.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 16000,
          "osl": 64,
          "max_concurrency": 32,
          "num_prompts": 128,
          "image_height": 3500,
          "image_width": 2500,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 121210.0,
              "tput_user": 5.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 24242.0,
              "tput_user": 25.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12121.0,
              "tput_user": 50.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "google/medgemma-27b-it",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"l1_small_size\": 768, \"fabric_config\": \"FABRIC_1D\"}",
        "mm-processor-kwargs": "{\"use_fast\": true, \"do_convert_rgb\": true, \"do_pan_and_scan\": true}"
      },
      "override_tt_config": {
        "l1_small_size": 768,
        "fabric_config": "FABRIC_1D"
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 27,
    "min_disk_gb": 74,
    "min_ram_gb": 108,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-17a5973-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/17a5973/models/tt_transformers",
    "override_tt_config": {
      "l1_small_size": 768,
      "fabric_config": "FABRIC_1D"
    },
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-8B_n150": {
    "model_id": "id_tt-transformers_Qwen3-8B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 940.0,
              "tput_user": 2.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 188.0,
              "tput_user": 10.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 94.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-8B_n300": {
    "model_id": "id_tt-transformers_Qwen3-8B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 620.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 124.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 62.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-8B_t3k": {
    "model_id": "id_tt-transformers_Qwen3-8B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 240.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 48.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 24.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-8B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen3-8B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-8B_galaxy": {
    "model_id": "id_tt-transformers_Qwen3-8B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-8B",
    "model_name": "Qwen3-8B",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 40960,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-8B",
        "block_size": "64",
        "max_model_len": "40960",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "40960",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4}"
      },
      "override_tt_config": {
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-32B_t3k": {
    "model_id": "id_tt-transformers_Qwen3-32B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 630.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 126.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 63.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-32B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen3-32B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 2,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 2,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen3-32B_galaxy": {
    "model_id": "id_tt-transformers_Qwen3-32B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen3-32B",
    "model_name": "Qwen3-32B",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen3-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4}"
      },
      "override_tt_config": {
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 3
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 3
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Mistral-7B-Instruct-v0.3_n150": {
    "model_id": "id_tt-transformers_Mistral-7B-Instruct-v0.3_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "model_name": "Mistral-7B-Instruct-v0.3",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 830.0,
              "tput_user": 2.4000000000000004,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 166.0,
              "tput_user": 12.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 83.0,
              "tput_user": 24.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "mistralai/Mistral-7B-Instruct-v0.3",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Mistral-7B-Instruct-v0.3_n300": {
    "model_id": "id_tt-transformers_Mistral-7B-Instruct-v0.3_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "model_name": "Mistral-7B-Instruct-v0.3",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 540.0,
              "tput_user": 5.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 108.0,
              "tput_user": 25.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 54.0,
              "tput_user": 50.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "mistralai/Mistral-7B-Instruct-v0.3",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Mistral-7B-Instruct-v0.3_t3k": {
    "model_id": "id_tt-transformers_Mistral-7B-Instruct-v0.3_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "mistralai/Mistral-7B-Instruct-v0.3",
    "model_name": "Mistral-7B-Instruct-v0.3",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 32768,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 210.0,
              "tput_user": 19.200000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 42.0,
              "tput_user": 96.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 21.0,
              "tput_user": 192.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "mistralai/Mistral-7B-Instruct-v0.3",
        "block_size": "64",
        "max_model_len": "32768",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "32768",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_QwQ-32B_t3k": {
    "model_id": "id_tt-transformers_QwQ-32B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/QwQ-32B",
    "model_name": "QwQ-32B",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 680.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 136.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 68.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/QwQ-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_QwQ-32B_galaxy": {
    "model_id": "id_tt-transformers_QwQ-32B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/QwQ-32B",
    "model_name": "QwQ-32B",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1000.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 200.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 100.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/QwQ-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 27381760, \"data_parallel\": 4}"
      },
      "override_tt_config": {
        "trace_region_size": 27381760,
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 3
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 3
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 27381760,
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_QwQ-32B_galaxy_t3k": {
    "model_id": "id_tt-transformers_QwQ-32B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/QwQ-32B",
    "model_name": "QwQ-32B",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/QwQ-32B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-72B_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B",
    "model_name": "Qwen2.5-72B",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1210.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 242.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 121.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 38720.0,
              "tput_user": 2.0,
              "tput": 64.0,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 7744.0,
              "tput_user": 10.0,
              "tput": 320.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 3872.0,
              "tput_user": 20.0,
              "tput": 640.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 26000000}"
      },
      "override_tt_config": {
        "trace_region_size": 26000000
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 288,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 26000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-72B_galaxy": {
    "model_id": "id_tt-transformers_Qwen2.5-72B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B",
    "model_name": "Qwen2.5-72B",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 130.0,
              "tput_user": 8.200000000000001,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 26.0,
              "tput_user": 41.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 13.0,
              "tput_user": 82.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 130.0,
              "tput_user": 8.200000000000001,
              "tput": 262.40000000000003,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 26.0,
              "tput_user": 41.0,
              "tput": 1312.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 13.0,
              "tput_user": 82.0,
              "tput": 2624.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 27381760, \"data_parallel\": 4}"
      },
      "override_tt_config": {
        "trace_region_size": 27381760,
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 288,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 27381760,
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-72B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B",
    "model_name": "Qwen2.5-72B",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 27381760}"
      },
      "override_tt_config": {
        "trace_region_size": 27381760
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 288,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 27381760
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-72B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5-72B-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 1210.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 242.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 121.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 38720.0,
              "tput_user": 2.0,
              "tput": 64.0,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 7744.0,
              "tput_user": 10.0,
              "tput": 320.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 3872.0,
              "tput_user": 20.0,
              "tput": 640.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 26000000}"
      },
      "override_tt_config": {
        "trace_region_size": 26000000
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 288,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 26000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy": {
    "model_id": "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5-72B-Instruct",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 130.0,
              "tput_user": 8.200000000000001,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 26.0,
              "tput_user": 41.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 13.0,
              "tput_user": 82.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 32,
          "num_prompts": 64,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 130.0,
              "tput_user": 8.200000000000001,
              "tput": 262.40000000000003,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 26.0,
              "tput_user": 41.0,
              "tput": 1312.0,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 13.0,
              "tput_user": 82.0,
              "tput": 2624.0,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 27381760, \"data_parallel\": 4}"
      },
      "override_tt_config": {
        "trace_region_size": 27381760,
        "data_parallel": 4
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 288,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 27381760,
      "data_parallel": 4
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-72B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5-72B-Instruct",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 27381760}"
      },
      "override_tt_config": {
        "trace_region_size": 27381760
      },
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MAX_PREFILL_CHUNK_SIZE": "16",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 72,
    "min_disk_gb": 164,
    "min_ram_gb": 288,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 27381760
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-7B_n300": {
    "model_id": "id_tt-transformers_Qwen2.5-7B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B",
    "model_name": "Qwen2.5-7B",
    "device_type": "N300",
    "tt_metal_commit": "v0.62.0-rc10",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 160.0,
              "tput_user": 6.6000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 32.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 16.0,
              "tput_user": 66.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "c348d08",
    "custom_inference_server": null,
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc10-c348d08",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc10/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-7B_n150x4": {
    "model_id": "id_tt-transformers_Qwen2.5-7B_n150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B",
    "model_name": "Qwen2.5-7B",
    "device_type": "N150X4",
    "tt_metal_commit": "v0.62.0-rc10",
    "device_model_spec": {
      "device": "N150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150x4",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150x4",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "c348d08",
    "custom_inference_server": null,
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc10-c348d08",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc10/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-7B-Instruct_n300": {
    "model_id": "id_tt-transformers_Qwen2.5-7B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B-Instruct",
    "model_name": "Qwen2.5-7B-Instruct",
    "device_type": "N300",
    "tt_metal_commit": "v0.62.0-rc10",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 160.0,
              "tput_user": 6.6000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 32.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 16.0,
              "tput_user": 66.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "c348d08",
    "custom_inference_server": null,
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc10-c348d08",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc10/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-7B-Instruct_n150x4": {
    "model_id": "id_tt-transformers_Qwen2.5-7B-Instruct_n150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-7B-Instruct",
    "model_name": "Qwen2.5-7B-Instruct",
    "device_type": "N150X4",
    "tt_metal_commit": "v0.62.0-rc10",
    "device_model_spec": {
      "device": "N150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150x4",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150x4",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "c348d08",
    "custom_inference_server": null,
    "param_count": 7,
    "min_disk_gb": 34,
    "min_ram_gb": 28,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc10-c348d08",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc10/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_llama3-70b-galaxy_Llama-3.3-70B-Instruct_galaxy": {
    "model_id": "id_llama3-70b-galaxy_Llama-3.3-70B-Instruct_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1345000, \"trace_region_size\": 192441344}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1345000,
        "trace_region_size": 192441344
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1345000,
      "trace_region_size": 192441344
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_llama3-70b-galaxy_Llama-3.1-70B_galaxy": {
    "model_id": "id_llama3-70b-galaxy_Llama-3.1-70B_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1345000, \"trace_region_size\": 192441344}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1345000,
        "trace_region_size": 192441344
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1345000,
      "trace_region_size": 192441344
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_llama3-70b-galaxy_Llama-3.1-70B-Instruct_galaxy": {
    "model_id": "id_llama3-70b-galaxy_Llama-3.1-70B-Instruct_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1345000, \"trace_region_size\": 192441344}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1345000,
        "trace_region_size": 192441344
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1345000,
      "trace_region_size": 192441344
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_llama3-70b-galaxy_DeepSeek-R1-Distill-Llama-70B_galaxy": {
    "model_id": "id_llama3-70b-galaxy_DeepSeek-R1-Distill-Llama-70B_galaxy",
    "impl": {
      "impl_id": "llama3_70b_galaxy",
      "impl_name": "llama3-70b-galaxy",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/llama3_70b_galaxy"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        },
        {
          "isl": 2048,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 8000.0,
              "tput_user": 8.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 1600.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 800.0,
              "tput_user": 80.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": 1,
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1345000, \"trace_region_size\": 192441344}"
      },
      "override_tt_config": {
        "dispatch_core_axis": "col",
        "sample_on_device_mode": "all",
        "fabric_config": "FABRIC_1D_RING",
        "worker_l1_size": 1345000,
        "trace_region_size": 192441344
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/demos/llama3_70b_galaxy",
    "override_tt_config": {
      "dispatch_core_axis": "col",
      "sample_on_device_mode": "all",
      "fabric_config": "FABRIC_1D_RING",
      "worker_l1_size": 1345000,
      "trace_region_size": 192441344
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.3-70B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.3-70B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-70B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-70B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_t3k": {
    "model_id": "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 380.0,
              "tput_user": 2.8000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 76.0,
              "tput_user": 14.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 38.0,
              "tput_user": 28.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.8.0",
        "mode": "SUGGESTED"
      },
      "kmd": {
        "specifier": ">=2.2.0",
        "mode": "SUGGESTED"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.3-70B-Instruct_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.3-70B-Instruct_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "device_type": "P150X4",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-70B_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-70B_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "device_type": "P150X4",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-70B-Instruct_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-70B-Instruct_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "device_type": "P150X4",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_p150x4": {
    "model_id": "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "device_type": "P150X4",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 960.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 192.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 96.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.5.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.3.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.3-70B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.3-70B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama-3.3-70B-Instruct",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "e7c329b",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-70B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B",
    "model_name": "Llama-3.1-70B",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "e7c329b",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-70B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-70B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-70B-Instruct",
    "model_name": "Llama-3.1-70B-Instruct",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-70B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "e7c329b",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_galaxy_t3k": {
    "model_id": "id_tt-transformers_DeepSeek-R1-Distill-Llama-70B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "v0.62.0-rc33",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": "32",
        "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": "32",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "e7c329b",
    "custom_inference_server": null,
    "param_count": 70,
    "min_disk_gb": 160,
    "min_ram_gb": 280,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.62.0-rc33-e7c329b",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc33/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-11B-Vision_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision",
    "model_name": "Llama-3.2-11B-Vision",
    "device_type": "N300",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3390.0,
              "tput_user": 3.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 678.0,
              "tput_user": 15.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 339.0,
              "tput_user": 31.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "custom_inference_server": null,
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 44,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-11B-Vision_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision",
    "model_name": "Llama-3.2-11B-Vision",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 950.0,
              "tput_user": 12.200000000000001,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 190.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 95.0,
              "tput_user": 122.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "custom_inference_server": null,
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 44,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "model_name": "Llama-3.2-11B-Vision-Instruct",
    "device_type": "N300",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3390.0,
              "tput_user": 3.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 678.0,
              "tput_user": 15.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 339.0,
              "tput_user": 31.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "custom_inference_server": null,
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 44,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-11B-Vision-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "model_name": "Llama-3.2-11B-Vision-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 16,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 950.0,
              "tput_user": 12.200000000000001,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 190.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 95.0,
              "tput_user": 122.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-11B-Vision-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "16",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "5cbc982",
    "custom_inference_server": null,
    "param_count": 11,
    "min_disk_gb": 42,
    "min_ram_gb": 44,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-90B-Vision_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-90B-Vision_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-90B-Vision",
    "model_name": "Llama-3.2-90B-Vision",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3030.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 606.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 303.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-90B-Vision",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": 16
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": 16
    },
    "vllm_commit": "5cbc982",
    "custom_inference_server": null,
    "param_count": 90,
    "min_disk_gb": 200,
    "min_ram_gb": 360,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-90B-Vision-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-90B-Vision-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-90B-Vision-Instruct",
    "model_name": "Llama-3.2-90B-Vision-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "v0.61.1-rc1",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": 512,
          "image_width": 512,
          "images_per_prompt": 1,
          "task_type": "image",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 3030.0,
              "tput_user": 2.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 606.0,
              "tput_user": 10.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 303.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-90B-Vision-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "MAX_PREFILL_CHUNK_SIZE": 16
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "MAX_PREFILL_CHUNK_SIZE": 16
    },
    "vllm_commit": "5cbc982",
    "custom_inference_server": null,
    "param_count": 90,
    "min_disk_gb": 200,
    "min_ram_gb": 360,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-v0.61.1-rc1-5cbc982",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/v0.61.1-rc1/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text",
      "image"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-1B_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-1B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B",
    "model_name": "Llama-3.2-1B",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 4,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-1B_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-1B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B",
    "model_name": "Llama-3.2-1B",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 4,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-1B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-1B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B",
    "model_name": "Llama-3.2-1B",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 4,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-1B-Instruct_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-1B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "model_name": "Llama-3.2-1B-Instruct",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 4,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-1B-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-1B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "model_name": "Llama-3.2-1B-Instruct",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 4,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-1B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-1B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-1B-Instruct",
    "model_name": "Llama-3.2-1B-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 60.0,
              "tput_user": 18.3,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 12.0,
              "tput_user": 91.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 6.0,
              "tput_user": 183.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-1B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 1,
    "min_disk_gb": 22,
    "min_ram_gb": 4,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-3B_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-3B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B",
    "model_name": "Llama-3.2-3B",
    "device_type": "N150",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "custom_inference_server": null,
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 12,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-3B_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-3B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B",
    "model_name": "Llama-3.2-3B",
    "device_type": "N300",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "custom_inference_server": null,
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 12,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-3B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-3B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B",
    "model_name": "Llama-3.2-3B",
    "device_type": "T3K",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "custom_inference_server": null,
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 12,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-3B-Instruct_n150": {
    "model_id": "id_tt-transformers_Llama-3.2-3B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama-3.2-3B-Instruct",
    "device_type": "N150",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "custom_inference_server": null,
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 12,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-3B-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.2-3B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama-3.2-3B-Instruct",
    "device_type": "N300",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "custom_inference_server": null,
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 12,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.2-3B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.2-3B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama-3.2-3B-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "20edc39",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 170.0,
              "tput_user": 6.1000000000000005,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 34.0,
              "tput_user": 30.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 17.0,
              "tput_user": 61.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.2-3B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "03cb300",
    "custom_inference_server": null,
    "param_count": 3,
    "min_disk_gb": 26,
    "min_ram_gb": 12,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-20edc39-03cb300",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/20edc39/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_n150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 890.0,
              "tput_user": 2.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 178.0,
              "tput_user": 10.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 89.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_n300": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 580.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 116.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 58.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 230.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 46.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 23.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_gpu": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_gpu",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "GPU",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "GPU",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": false,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "GPU"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "GPU"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_n150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "N150",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 890.0,
              "tput_user": 2.1,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 178.0,
              "tput_user": 10.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 89.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_n300": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "N300",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 580.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 116.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 58.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 230.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 46.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 23.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_gpu": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_gpu",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "GPU",
    "tt_metal_commit": "9b67e09",
    "device_model_spec": {
      "device": "GPU",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": false,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "GPU"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "GPU"
    },
    "vllm_commit": "a91b644",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-9b67e09-a91b644",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/9b67e09/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_p100": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_p100",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "P100",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P100",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 570.0,
              "tput_user": 3.3000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 114.0,
              "tput_user": 16.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 57.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P100",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P100",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_p150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_p150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "P150",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "P150",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_p100": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_p100",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "P100",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P100",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 570.0,
              "tput_user": 3.3000000000000003,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 114.0,
              "tput_user": 16.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 57.0,
              "tput_user": 33.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"trace_region_size\": 30000000}"
      },
      "override_tt_config": {
        "trace_region_size": 30000000
      },
      "env_vars": {
        "MESH_DEVICE": "P100",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P100",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "trace_region_size": 30000000
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_p150": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_p150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "P150",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 300.0,
              "tput_user": 3.7,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 60.0,
              "tput_user": 18.5,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 30.0,
              "tput_user": 37.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "P150",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "P150X4",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 4.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4, \"sample_on_device_mode\": \"decode_only\"}"
      },
      "override_tt_config": {
        "data_parallel": 4,
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4,
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "P150",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_p150x4": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_p150x4",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "P150X4",
    "tt_metal_commit": "55fd115",
    "device_model_spec": {
      "device": "P150X4",
      "max_concurrency": 128,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 500.0,
              "tput_user": 4.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 100.0,
              "tput_user": 20.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 50.0,
              "tput_user": 40.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4, \"sample_on_device_mode\": \"decode_only\"}"
      },
      "override_tt_config": {
        "data_parallel": 4,
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "MESH_DEVICE": "P150x4",
        "ARCH_NAME": "blackhole"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "P150x4",
      "ARCH_NAME": "blackhole"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-55fd115-aa4ae1e",
    "status": "COMPLETE",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/55fd115/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4,
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "P150",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_galaxy": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 110.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 22.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 11.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4, \"sample_on_device_mode\": \"decode_only\"}"
      },
      "override_tt_config": {
        "data_parallel": 4,
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4,
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B",
    "model_name": "Llama-3.1-8B",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 128,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 110.0,
              "tput_user": 17.0,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 22.0,
              "tput_user": 85.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 11.0,
              "tput_user": 170.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "128",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{\"data_parallel\": 4, \"sample_on_device_mode\": \"decode_only\"}"
      },
      "override_tt_config": {
        "data_parallel": 4,
        "sample_on_device_mode": "decode_only"
      },
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {
      "data_parallel": 4,
      "sample_on_device_mode": "decode_only"
    },
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": "T3K",
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Llama-3.1-8B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama-3.1-8B-Instruct",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MM_THROTTLE_PERF": 5,
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": {
      "firmware": {
        "specifier": ">=18.6.0",
        "mode": "STRICT"
      },
      "kmd": {
        "specifier": ">=2.1.0",
        "mode": "STRICT"
      }
    },
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MM_THROTTLE_PERF": 5,
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "2dcee0c",
    "custom_inference_server": null,
    "param_count": 8,
    "min_disk_gb": 36,
    "min_ram_gb": 32,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-2496be4-2dcee0c",
    "status": "FUNCTIONAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "model_name": "Qwen2.5-Coder-32B-Instruct",
    "device_type": "T3K",
    "tt_metal_commit": "17a5973",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": 128,
          "osl": 128,
          "max_concurrency": 1,
          "num_prompts": 8,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "text",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 630.0,
              "tput_user": 4.2,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 126.0,
              "tput_user": 21.0,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 63.0,
              "tput_user": 42.0,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-17a5973-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/17a5973/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_galaxy_t3k": {
    "model_id": "id_tt-transformers_Qwen2.5-Coder-32B-Instruct_galaxy_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "model_name": "Qwen2.5-Coder-32B-Instruct",
    "device_type": "GALAXY_T3K",
    "tt_metal_commit": "17a5973",
    "device_model_spec": {
      "device": "GALAXY_T3K",
      "max_concurrency": 32,
      "max_context": 131072,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [],
      "vllm_args": {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "block_size": "64",
        "max_model_len": "131072",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "131072",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0",
        "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "VLLM_ALLOW_LONG_MAX_MODEL_LEN": 1,
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0",
      "TT_MESH_GRAPH_DESC_PATH": "../../tt-metal/tt_metal/fabric/mesh_graph_descriptors/t3k_mesh_graph_descriptor.yaml"
    },
    "vllm_commit": "aa4ae1e",
    "custom_inference_server": null,
    "param_count": 32,
    "min_disk_gb": 84,
    "min_ram_gb": 128,
    "model_type": "LLM",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-inference-server/vllm-tt-metal-src-release-ubuntu-22.04-amd64:0.2.0-17a5973-aa4ae1e",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/17a5973/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_n150": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_n150",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_n300": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_n300",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "device_type": "N300",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N300",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "N300",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "N300",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_t3k": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 4,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 4,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "4",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_stable-diffusion-xl-base-1.0_galaxy": {
    "model_id": "id_tt-transformers_stable-diffusion-xl-base-1.0_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "stable-diffusion-xl-base-1.0",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 32,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 125000.0,
              "tput_user": 0.008,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 25000.0,
              "tput_user": 0.04,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 12500.0,
              "tput_user": 0.08,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_stable-diffusion-3.5-large_t3k": {
    "model_id": "id_tt-transformers_stable-diffusion-3.5-large_t3k",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-3.5-large",
    "model_name": "stable-diffusion-3.5-large",
    "device_type": "T3K",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "T3K",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 110000.0,
              "tput_user": 0.0091,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 22000.0,
              "tput_user": 0.0455,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 11000.0,
              "tput_user": 0.091,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-3.5-large",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
        "MESH_DEVICE": "T3K",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "WH_ARCH_YAML": "wormhole_b0_80_arch_eth_dispatch.yaml",
      "MESH_DEVICE": "T3K",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_tt-transformers_stable-diffusion-3.5-large_galaxy": {
    "model_id": "id_tt-transformers_stable-diffusion-3.5-large_galaxy",
    "impl": {
      "impl_id": "tt_transformers",
      "impl_name": "tt-transformers",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/tt_transformers"
    },
    "hf_model_repo": "stabilityai/stable-diffusion-3.5-large",
    "model_name": "stable-diffusion-3.5-large",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "cnn",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 50000.0,
              "tput_user": 0.020000000000000004,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 10000.0,
              "tput_user": 0.1,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 5000.0,
              "tput_user": 0.2,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "stabilityai/stable-diffusion-3.5-large",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "CNN",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/tt_transformers",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": null
  },
  "id_whisper_openai-whisper-large-v3_n150": {
    "model_id": "id_whisper_openai-whisper-large-v3_n150",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "openai-whisper-large-v3",
    "model_name": "openai-whisper-large-v3",
    "device_type": "N150",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "N150",
      "max_concurrency": 1,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 4000.0,
              "tput_user": null,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 800.0,
              "tput_user": null,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 400.0,
              "tput_user": null,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "openai-whisper-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "1",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "N150",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "N150",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": "openai-whisper-large-v3"
  },
  "id_whisper_openai-whisper-large-v3_galaxy": {
    "model_id": "id_whisper_openai-whisper-large-v3_galaxy",
    "impl": {
      "impl_id": "whisper",
      "impl_name": "whisper",
      "repo_url": "https://github.com/tenstorrent/tt-metal",
      "code_path": "models/demos/whisper"
    },
    "hf_model_repo": "openai-whisper-large-v3",
    "model_name": "openai-whisper-large-v3",
    "device_type": "GALAXY",
    "tt_metal_commit": "2496be4",
    "device_model_spec": {
      "device": "GALAXY",
      "max_concurrency": 32,
      "max_context": 65536,
      "perf_targets_map": {},
      "default_impl": true,
      "perf_reference": [
        {
          "isl": null,
          "osl": null,
          "max_concurrency": 1,
          "num_prompts": null,
          "image_height": null,
          "image_width": null,
          "images_per_prompt": null,
          "task_type": "audio",
          "theoretical_ttft_ms": null,
          "theoretical_tput_user": null,
          "targets": {
            "functional": {
              "ttft_ms": 4000.0,
              "tput_user": null,
              "tput": null,
              "tolerance": 0.0
            },
            "complete": {
              "ttft_ms": 800.0,
              "tput_user": null,
              "tput": null,
              "tolerance": 0.0
            },
            "target": {
              "ttft_ms": 400.0,
              "tput_user": null,
              "tput": null,
              "tolerance": 0.0
            }
          },
          "target_peak_perf": {
            "customer_functional": 0.1,
            "customer_complete": 0.5,
            "customer_sellable": 0.8
          },
          "num_inference_steps": null
        }
      ],
      "vllm_args": {
        "model": "openai-whisper-large-v3",
        "block_size": "64",
        "max_model_len": "65536",
        "max_num_seqs": "32",
        "max_num_batched_tokens": "65536",
        "num_scheduler_steps": "10",
        "max-log-len": "32",
        "seed": "9472",
        "override_tt_config": "{}"
      },
      "override_tt_config": {},
      "env_vars": {
        "MESH_DEVICE": "TG",
        "ARCH_NAME": "wormhole_b0"
      }
    },
    "system_requirements": null,
    "env_vars": {
      "VLLM_CONFIGURE_LOGGING": "1",
      "VLLM_RPC_TIMEOUT": "900000",
      "VLLM_TARGET_DEVICE": "tt",
      "MESH_DEVICE": "TG",
      "ARCH_NAME": "wormhole_b0"
    },
    "vllm_commit": null,
    "custom_inference_server": null,
    "param_count": null,
    "min_disk_gb": 15,
    "min_ram_gb": 6,
    "model_type": "AUDIO",
    "repacked": 0,
    "version": "0.2.0",
    "docker_image": "ghcr.io/tenstorrent/tt-media-inference-server:0.2.0-2496be4518bca0a7a5b497a4cda3cfe7e2f59756",
    "status": "EXPERIMENTAL",
    "code_link": "https://github.com/tenstorrent/tt-metal/tree/2496be4/models/demos/whisper",
    "override_tt_config": {},
    "supported_modalities": [
      "text"
    ],
    "subdevice_type": null,
    "uses_tensor_model_cache": true,
    "cli_args": {},
    "display_name": "openai-whisper-large-v3"
  }
}