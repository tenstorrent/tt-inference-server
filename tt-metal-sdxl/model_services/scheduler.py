# SPDX-License-Identifier: Apache-2.0
#
# SPDX-FileCopyrightText: Â© 2025 Tenstorrent AI ULC

import asyncio
from multiprocessing import Process, Queue as Queue  # Need multiprocessing queues
import os
from threading import Lock
import time

from fastapi import HTTPException
from config.settings import get_settings
from model_services.device_worker import device_worker
from utils.helpers import log_execution_time
from utils.logger import TTLogger

class Scheduler:
    @log_execution_time("Scheduler init")
    def __init__(self):
        self.settings = get_settings()
        self.logger = TTLogger()
        self._setup_initial_variables()
        self._start_queues()

    def _start_queues(self):
        worker_count = self.get_worker_count()
        self.task_queue = Queue(self._get_max_queue_size())
        self.warmup_signals_queue = Queue(worker_count)
        self.result_queue = Queue()
        self.error_queue = Queue()

    def get_worker_count(self):
        if not hasattr(self, 'worker_count'):
            self.worker_count = self._calculate_worker_count()
        return self.worker_count

    def _setup_initial_variables(self):
        self.isReady = False
        self.listener_running = True
        self.device_warmup_listener_running = True
        self.workers_to_open = []
        self.worker_info = {}
        self.monitor_running = True
        self.result_futures = {}
        # locks
        self.result_futures_lock = Lock()
        # Task references for asyncio tasks
        self.monitor_task_ref = None
        self.listener_task_ref = None
        self.device_warmup_listener_ref = None
        self.error_queue_listener_ref = None

    def is_queue_full(self):
        return self.task_queue.full()

    @log_execution_time("Scheduler request processing")
    def process_request(self, request):
        try:
            self.check_is_model_ready()
            
            if self.task_queue.full():
                raise HTTPException(
                    status_code=429, 
                    detail="Task queue is full. Please try again later."
                )
            
            # Non-blocking put with timeout
            try:
                self.task_queue.put(request, timeout=1.0)
            except:
                raise HTTPException(
                    status_code=429,
                    detail="Unable to queue request - system busy"
                )
                
        except HTTPException:
            raise
        except Exception as e:
            self.logger.error(f"Error processing request: {e}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail="Internal error processing request"
            )

    def check_is_model_ready(self) -> bool:
        if self.isReady is not True:
            raise HTTPException(405, "Model is not ready")
        return True

    @log_execution_time("Scheduler - starting workers")
    def start_workers(self):
        # keep result listener in the main event loop
        self.listener_task_ref = asyncio.create_task(self.result_listener())

        # keep device warmup listener in the main event loop, it'll close soon
        self.device_warmup_listener_ref = asyncio.create_task(self.device_warmup_listener())
        # keep error listener in the main event loop
        self.error_queue_listener_ref = asyncio.create_task(self.error_listener())

        self.logger.info(f"Workers to start: {self.worker_count}")
        asyncio.create_task(self._start_workers_in_sequence())
    
    async def _start_workers_in_sequence(self):
        """Start workers one by one with a delay to avoid overload"""
        while self.workers_to_open:
            self._start_worker()
            self.logger.info(f"Worker started, remaining workers to open: {len(self.workers_to_open)}")
            
            # Add delay between worker starts to avoid resource contention
            if self.workers_to_open:  # Only sleep if there are more workers to start
                await asyncio.sleep(self.settings.new_device_delay_seconds)
    
        self.logger.info("All workers started in sequence")

    def _start_worker(self, worker_id = None):
        """Start a single worker process"""
        if (worker_id is None):
            worker_id = self.workers_to_open.pop(0) if self.workers_to_open else Exception("No more workers to start")
            # in case it's a device pair remove starting bracket open
            worker_id = worker_id.lstrip('(').rstrip(')')
        self.logger.info(f"Starting worker {worker_id}")
        p = Process(
            target=device_worker, 
            args=(worker_id, self.task_queue, self.result_queue, self.warmup_signals_queue, self.error_queue),
            name=f"DeviceWorker-{worker_id}"
        )
        p.start()
            
        self.worker_info[worker_id] = {
            'process': p,
            'start_time': time.time(),
            'restart_count': 0,
            'is_ready': False,
            'error_count': 0
        }
        
        self.logger.info(f"Started worker {worker_id} with PID {p.pid}")

    def restart_worker(self, worker_id: str):
        """Restart a dead worker"""
        old_info = self.worker_info.get(worker_id, {})

        if old_info == {}:
            raise ValueError(f"Worker ID {worker_id} not found in worker info")

        restart_count = old_info.get('restart_count', 0) + 1
        
        self.logger.warning(f"Restarting dead worker {worker_id} (restart #{restart_count})")
        
        # Clean up old process if it exists
        if worker_id in self.worker_info:
            try:
                old_process = self.worker_info[worker_id]['process']
                if old_process.is_alive():
                    old_process.terminate()
                    old_process.join(timeout=5.0)
            except Exception as e:
                self.logger.error(f"Error cleaning up old worker {worker_id}: {e}")
                self.logger.info(f"Old worker {worker_id} process does not exist")
        
        # Start new worker
        self._start_worker(worker_id)
        self.worker_info[worker_id]['restart_count'] = restart_count
        # pass the error count from old worker -1 to give it a chance to recover
        self.worker_info[worker_id]['error_count'] = old_info.get('error_count', 1) - 1

    async def result_listener(self):
        while self.listener_running:
            try:
                worker_id, task_id, input = await asyncio.to_thread(self.result_queue.get)
                
                if task_id is None:
                    self.listener_running = False
                    break
                
                # Thread-safe access to futures
                with self.result_futures_lock:
                    future = self.result_futures.pop(task_id, None)
                
                if future and not future.cancelled():
                    future.set_result(input)
                elif not future:
                    self.logger.warning(f"No future found for task {task_id}")
                
                # do this later, it doesn't affect the result processing
                # one sucesfull job = worker ID restart
                self.worker_info[worker_id]['restart_count'] = 0
                    
            except Exception as e:
                self.logger.error(f"Error in result_listener: {e}", exc_info=True)
        
        self.logger.info("Result listener stopped")

    async def error_listener(self):
        while self.listener_running:
            try:
                worker_id, task_id, error = await asyncio.to_thread(self.error_queue.get)
                
                self.worker_info[worker_id]['error_count'] += 1
                
                self.logger.warning(f"Worker {worker_id} error cound is : {self.worker_info[worker_id]['error_count']}")
                
                if task_id is None:
                    self.listener_running = False
                    break
                
                self.logger.error(f"Error in worker {task_id}: {error}")
                
                # Thread-safe future handling
                with self.result_futures_lock:
                    future = self.result_futures.pop(task_id, None)
                
                if future and not future.cancelled():
                    future.set_exception(Exception(error))
                    
            except Exception as e:
                self.logger.error(f"Error in error_listener: {e}", exc_info=True)
        
        self.logger.info("Error listener stopped")

    async def device_warmup_listener(self):
        while self.device_warmup_listener_running:
            try:
                device_id = await asyncio.to_thread(self.warmup_signals_queue.get)
                if device_id is None:  # Shutdown signal
                    break
                
                self.logger.info(f"Device {device_id} is warmed up")
                
                # Thread-safe device tracking
                self.worker_info[device_id]['is_ready'] = True
                # Set ready as soon as first device is available
                if not self.isReady:
                    self.isReady = True
                    
                    self.logger.info("First device warmed up, starting worker health monitor")
                    self.monitor_task_ref = asyncio.create_task(self.worker_health_monitor())

                all_devices_ready = all(info['is_ready'] for info in self.worker_info.values())
                if all_devices_ready:
                    self.logger.info("All devices are warmed up and ready")
            
            except Exception as e:
                self.logger.error(f"Error in device_warmup_listener: {e}", exc_info=True)
        
        self.logger.info("Device warmup listener is done")

    @log_execution_time("Scheduler - stopping workers")
    def stop_workers(self):
        self.logger.info("Stopping workers")
        
        try:
            # Stop monitoring
            self.monitor_running = False
            if self.monitor_task_ref:
                self.monitor_task_ref.cancel()
            
            # Stop accepting new requests
            self.isReady = False
            
            # Send shutdown signals to all workers
            for _ in self.worker_info:
                try:
                    self.task_queue.put(None, timeout=2.0)
                except:
                    self.logger.warning("Timeout sending shutdown signal to worker")
            
            # Wait for processes to finish gracefully
            for i, worker_element in self.worker_info.items():
                worker = worker_element['process']
                if worker.is_alive():
                    worker.join(timeout=10.0)  # Increased timeout
                    if worker.is_alive():
                        self.logger.warning(f"Worker {i} did not shutdown gracefully")
                        worker.terminate()  # Terminate process (not kill)
                        worker.join(timeout=2.0)  # Wait for termination
                        if worker.is_alive():
                            worker.kill()  # Force kill as last resort
            
            self.worker_info = {}  # Clear worker info
            
            self.logger.info("All workers stopped successfully")
            
            # Stop listeners
            self.listener_running = False
            self.device_warmup_listener_running = False
            
            # Send shutdown signals to listeners
            try:
                self.result_queue.put((None, None, None), timeout=1.0)
                self.error_queue.put((None, None, None), timeout=1.0)
                self.warmup_signals_queue.put(None, timeout=1.0)
            except:
                self.logger.warning("Timeout sending shutdown signals to listeners")

            # close queues
            self._close_queues(
                [self.task_queue, 
                 self.result_queue, 
                 self.warmup_signals_queue, 
                 self.error_queue])

            self.logger.info("Queues closed successfully")

            # Cancel any remaining futures
            with self.result_futures_lock:
                for task_id, future in self.result_futures.items():
                    if not future.done():
                        future.cancel()
                        self.logger.info(f"Cancelled pending task {task_id}")
                self.result_futures.clear()
            
            self.logger.info("Workers stopped")
            
        except Exception as e:
            self.logger.error(f"Error during worker shutdown: {e}", exc_info=True)

    def _close_queues(self, queues: list[Queue]):
        queues_closed = 0
        for idx, queue in enumerate(queues):
            try:
                queue.close()
                queue.join_thread()
                queues_closed += 1
            except Exception as e:
                self.logger.error(f"Error closing queue #{idx}: {e}")

        self.logger.info(f"Queues ({queues_closed}) closed successfully")

    def _calculate_worker_count(self) -> int:
        try:
            worker_count = len(self.settings.device_ids.split("),("))
            self.workers_to_open = self.settings.device_ids.split("),(")
            if worker_count < 1:
                self.logger.error("Worker count is 0")
                raise ValueError("Worker count must be at least 1")
            return worker_count
        except Exception as e:
            self.logger.error(f"Erros getting workers cannot: {e}")
            raise HTTPException(status_code=500, detail="Workers cannot be initialized")

    def _get_max_queue_size(self) -> int:
        try:
            max_queue_size = self.settings.max_queue_size
            if max_queue_size < 1:
                self.logger.error("Max queue size is 0")
                raise ValueError("Max queue size must be at least 1")
            return max_queue_size
        except Exception as e:
            self.logger.error(f"Error getting max queue size: {e}")
            raise HTTPException(status_code=500, detail="Max queue size not provided in settings")

    async def worker_health_monitor(self):
        """Monitor worker health and restart dead workers"""
        while self.monitor_running and self.isReady:
            try:
                dead_workers = []

                for worker_id, info in self.worker_info.items():
                    try:                        
                        process = info['process']
                        if not process.is_alive():
                            dead_workers.append(worker_id)
                    except Exception as e:
                        self.logger.error(f"Error checking worker {worker_id} health: {e}")
                        dead_workers.append(worker_id)
                
                # check for any workerrs that have too many errors
                for worker_id, info in self.worker_info.items():
                    if info['error_count'] > self.settings.max_worker_restart_count:
                        dead_workers.append(worker_id)
                        self.logger.error(f"Worker {worker_id} has too many errors ({info['error_count']}), restarting")

                self.logger.info(f"Worker health check: {len(dead_workers)} dead workers found")
                # Restart dead workers
                for worker_id in dead_workers:
                    restart_count = self.worker_info[worker_id].get('restart_count', 0)
                    
                    # Optional: Limit restart attempts
                    if restart_count < self.settings.max_worker_restart_count:  # Max 5 restarts per worker
                        self.restart_worker(worker_id)
                    else:
                        self.logger.error(f"Worker {worker_id} has died too many times ({restart_count}), restart did not help")
                        if self.settings.allow_deep_reset:
                            self.logger.info("Trying deep restart of all workers")
                            self.deep_restart_workers()

                await asyncio.sleep(self.settings.worker_check_sleep_timeout)
                
            except Exception as e:
                self.logger.error(f"Error in worker_health_monitor: {e}", exc_info=True)
                await asyncio.sleep(1.0)
        
        self.logger.info("Worker health monitor stopped")
    
    async def deep_restart_workers(self):
        """Restart all workers"""
        self.logger.info("Deep restarting all workers")
        
        # Stop current workers
        self.stop_workers()

        # try to reset the device
        exit_code = os.system(self.settings.reset_device_command)
        
        # Clear worker info
        self.worker_info.clear()
        
        self.logger.info(f"Reset command executed with exit code: {exit_code}")

        # Wait for a short period to ensure all processes are cleaned up
        await asyncio.sleep(self.settings.reset_device_sleep_time)
        
        self.logger.info("Restarting queues after reset")
        
        self._setup_initial_variables()
        self._start_queues()
        
        self.logger.info("Starting new workers after reset")
        
        # Start new workers
        self.start_workers()
        
        self.logger.info("All workers restarted successfully")

    def get_worker_info(self) -> dict:
        """Get serializable worker information for monitoring"""
        serializable_worker_info = {}
        for worker_id, info in self.worker_info.items():
            serializable_worker_info[worker_id] = {
                'pid': info['process'].pid if info['process'].is_alive() else None,
                'is_alive': info['process'].is_alive(),
                'start_time': info['start_time'],
                'is_ready': info['is_ready'],
                'restart_count': info['restart_count'],
                'error_count': info['error_count']
            }
        return serializable_worker_info